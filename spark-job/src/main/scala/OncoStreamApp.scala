import org.apache.spark.sql.SparkSession

object OncoStreamApp {
  def main(args: Array[String]): Unit = {
    
    // 1. Initialiser le Cerveau (Spark Session)
    val spark = SparkSession.builder()
      .appName("OncoStream-Ingestion")
      // "local[*]" signifie : Utilise tous les c≈ìurs de MON processeur (mode test)
      .master("local[*]")
      .getOrCreate()

    // On r√©duit le bruit (logs) pour ne voir que les erreurs ou les donn√©es
    spark.sparkContext.setLogLevel("WARN")
    
    println("üß¨ D√©marrage du Job Spark OncoStream...")

    // 2. L'Oreille : Configuration de la lecture Kafka
    // Note : On utilise 'localhost:9092' car tu lances ce code depuis WSL (l'ext√©rieur du conteneur)
    val kafkaStream = spark.readStream
      .format("kafka")
      .option("kafka.bootstrap.servers", "kafka:29092") 
      .option("subscribe", "ngs-raw-reads") // Le topic cr√©√© par ton script Python
      .option("startingOffsets", "latest")    // On √©coute seulement les nouveaux messages
      .load()

    // 3. La Traduction : Kafka envoie des octets (binaire), on veut du texte
    import spark.implicits._
    val dataStream = kafkaStream.selectExpr("CAST(value AS STRING) as fastq_data")

    // 4. LE STOCKAGE : √âcriture dans HDFS au format Parquet
    val query = dataStream.writeStream
      .outputMode("append")
      .format("parquet") // Format optimis√© Big Data
      // L'adresse du Namenode (d√©finie dans docker-compose)
      .option("path", "hdfs://namenode:9000/oncostream/raw_data")
      // OBLIGATOIRE : Spark doit noter o√π il s'est arr√™t√© pour ne pas perdre de donn√©es
      .option("checkpointLocation", "hdfs://namenode:9000/oncostream/checkpoints/raw")
      .start()

    // Garde le programme allum√© ind√©finiment
    query.awaitTermination()
  }
}