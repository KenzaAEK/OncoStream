# ==============================================================================
# üß¨ PIPELINE CI/CD ONCOSTREAM
# ==============================================================================
# Description : Pipeline compl√®te pour projet Big Data (Spark, Kafka, HBase)
# Structure   : Lint -> Build -> Unit Test -> Integration Test -> Docker Package -> Deploy
# ==============================================================================

image: docker:24.0.5

services:
  # Service Docker-in-Docker n√©cessaire pour construire des images et lancer docker-compose
  - docker:24.0.5-dind

variables:
  # --- Versions des outils ---
  SCALA_SBT_IMAGE: "hseeberger/scala-sbt:11.0.18_1.9.7_3.3.1"
  PYTHON_IMAGE: "python:3.10-slim"
  
  # --- Optimisation Docker ---
  DOCKER_DRIVER: overlay2
  DOCKER_TLS_CERTDIR: "" # D√©sactiv√© pour faciliter la com entre dind et le runner
  COMPOSE_PROJECT_NAME: oncostream-ci # Nom fixe pour le r√©seau docker

  # --- Noms des Applications ---
  SPARK_APP_NAME: "oncostream-spark"
  PRODUCER_APP_NAME: "oncostream-producer"
  DASHBOARD_APP_NAME: "oncostream-dashboard"

# D√©finition des √©tapes dans l'ordre d'ex√©cution
stages:
  - validate      # Qualit√© du code (Linting)
  - build         # Compilation (Jars, Bytecode)
  - test          # Tests Unitaires (Mocks)
  - integration   # Tests de bout en bout (Vrai Kafka/HBase) - LE RETOUR !
  - package       # Cr√©ation et Push des images Docker
  - deploy        # D√©ploiement

# ============================================================
# STAGE 1: VALIDATION (Qualit√© du Code)
# ============================================================

validate:python-lint:
  stage: validate
  image: $PYTHON_IMAGE
  before_script:
    - pip install flake8 black
  script:
    - echo "üîç Validation du code Python (Style & Syntaxe)..."
    - flake8 data-generator/ --max-line-length=100 --ignore=E501,W503
    - flake8 dashboard/ --max-line-length=100 --ignore=E501,W503
    - black --check data-generator/ dashboard/
  allow_failure: true # On ne bloque pas la pipeline pour du style

validate:scala-format:
  stage: validate
  image: $SCALA_SBT_IMAGE
  script:
    - echo "üîç Validation du formatage Scala..."
    - cd spark-job
    - sbt scalafmtCheck || echo "‚ö†Ô∏è Format non conforme (non bloquant)"
  allow_failure: true

# ============================================================
# STAGE 2: BUILD (Compilation)
# ============================================================

build:scala-spark:
  stage: build
  image: $SCALA_SBT_IMAGE
  script:
    - echo "üî® Compilation du job Spark (Scala)..."
    - cd spark-job
    - sbt clean compile package
  artifacts:
    # On sauvegarde le JAR g√©n√©r√© pour l'utiliser dans l'√©tape 'package'
    paths:
      - spark-job/target/scala-2.12/*.jar
    expire_in: 1 hour
  cache:
    key: sbt-cache
    paths:
      - spark-job/.ivy2/
      - spark-job/.sbt/

build:python-checks:
  stage: build
  image: $PYTHON_IMAGE
  script:
    - echo "üî® V√©rification de la compilation Python..."
    - cd data-generator
    - pip install -r requirements.txt
    - python -m py_compile ngs_producer.py # V√©rifie qu'il n'y a pas d'erreur de syntaxe grave
  artifacts:
    paths:
      - data-generator/*.pyc

# ============================================================
# STAGE 3: TEST (Tests Unitaires - Rapides & Isol√©s)
# ============================================================

test:scala-unit:
  stage: test
  image: $SCALA_SBT_IMAGE
  dependencies:
    - build:scala-spark
  script:
    - echo "üß™ Tests Unitaires Scala..."
    - cd spark-job
    - sbt test
  artifacts:
    reports:
      junit: spark-job/target/test-reports/*.xml

test:python-producer:
  stage: test
  image: $PYTHON_IMAGE
  dependencies:
    - build:python-checks
  before_script:
    - pip install pytest pytest-cov pytest-mock
    - cd data-generator && pip install -r requirements.txt
  script:
    - echo "üß™ Tests Unitaires Python (avec Mocks)..."
    - pytest tests/ -v --cov=. --cov-report=term
  coverage: '/TOTAL.*\s+(\d+%)$/'

# ============================================================
# STAGE 4: INTEGRATION (Test R√©el End-to-End)
# ============================================================
# C'est ici qu'on corrige ton erreur pr√©c√©dente (exit code 1/125).
# On lance toute l'infra pour v√©rifier que Kafka et HBase parlent bien ensemble.

integration:full-stack:
  stage: integration
  image: docker/compose:latest
  services:
    - docker:dind
  script:
    - echo "üèóÔ∏è D√©marrage de l'infrastructure compl√®te..."
    # On build les images locales pour le test
    - docker-compose --profile bonus up -d --build
    
    - echo "‚è≥ Attente (45s) pour Kafka et HBase..."
    - sleep 45
    
    - echo "üõ†Ô∏è Initialisation HBase..."
    - docker exec -i hbase hbase shell < hbase-config/init-script.txt
    
    - echo "üß¨ Lancement du test Producer (CORRECTIF)..."
    # IMPORTANT : On utilise 'docker-compose run' au lieu de 'docker run'.
    # Cela g√®re automatiquement le r√©seau (network) et les variables d'environnement.
    # --rm supprime le conteneur apr√®s le test.
    - docker-compose --profile bonus run --rm -e KAFKA_BOOTSTRAP_SERVERS=kafka:29092 oncostream-producer --duration 10
    
    - echo "‚úÖ V√©rification : Y a-t-il des donn√©es dans HBase ?"
    # On scanne la table et on v√©rifie qu'on a au moins 1 ligne
    - echo "scan 'oncostream_realtime'" | docker exec -i hbase hbase shell | grep "row(s)"
    
  after_script:
    - echo "üßπ Nettoyage de l'environnement de test..."
    - docker-compose --profile bonus down -v
  only:
    - main
    - merge_requests

# ============================================================
# STAGE 5: PACKAGE (Build & Push Docker Registry)
# ============================================================

package:docker-images:
  stage: package
  image: docker:24.0.5
  services:
    - docker:24.0.5-dind
  before_script:
    # Connexion au registre GitLab
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - echo "üì¶ Build & Push des images finales..."
    
    # 1. Producer
    - cd data-generator
    - docker build -t $CI_REGISTRY_IMAGE/producer:$CI_COMMIT_SHORT_SHA -t $CI_REGISTRY_IMAGE/producer:latest .
    - docker push $CI_REGISTRY_IMAGE/producer:$CI_COMMIT_SHORT_SHA
    - docker push $CI_REGISTRY_IMAGE/producer:latest
    - cd ..
    
    # 2. Spark App (Utilise le JAR compil√© au stage 'build')
    - cd spark-job
    - docker build -t $CI_REGISTRY_IMAGE/spark-app:$CI_COMMIT_SHORT_SHA -t $CI_REGISTRY_IMAGE/spark-app:latest .
    - docker push $CI_REGISTRY_IMAGE/spark-app:$CI_COMMIT_SHORT_SHA
    - docker push $CI_REGISTRY_IMAGE/spark-app:latest
  dependencies:
    - build:scala-spark # R√©cup√®re le .jar
  only:
    - main

# ============================================================
# STAGE 6: DEPLOY (Manuel)
# ============================================================

deploy:staging:
  stage: deploy
  image: docker/compose:latest
  script:
    - echo "üöÄ Simulation de d√©ploiement STAGING..."
    - echo "Images pr√™tes : $CI_REGISTRY_IMAGE/producer:$CI_COMMIT_SHORT_SHA"
  environment:
    name: staging
  when: manual
  only:
    - main